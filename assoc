#!/usr/bin/python3

from PyPDF2 import PdfReader
import tempfile
import urllib.request
import PyPDF2
import io
import os

import sys
from todoist_api_python.api import TodoistAPI
from todoist_api_python.models import Attachment, Comment, Task

def gen_head(title, wtype="main"): 
    if wtype == "main":
        return f'''<html><head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>{title}</title>
        <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="include/main.css"/>
        <link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
        </head>
        <body>
        '''
    elif wtype == "wiki" or wtype == "readable":
        return f'''<html><head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>{title}</title>
        <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../include/main.css"/>
        </head>
        <body>
        '''

def gen_banner():
    return f''' <div class="content">
    <h1>Association Citation</h1>
	<div class='teaser-box'>
	<img class='teaser-img' src='include/img/pixel_book.jpg'></img>
	</div>
	<h2>Stage 4: Comment Frenzy<h2>
    <a href="./twitter_gallery.html">Twitter Gallery(Click Here)</a>
    </div>
    '''

def gen_p(text):
    return f'<div class="content" id="content"><p id="entry">{text}</p></div>'

def gen_readp(text):
    return f'''<p id="page">{text}</p>'''

def gen_pagenum(pagenum):
    return f'''<div id="pagenum"><p>{pagenum}</p></div>'''

def gen_tail():
    return f'''</div>
    </body>
    </html>
    '''
def FROZEN_gen_download_p(displayname, link, codename):
    nlink = "routes/" + codename + ".html"
    rlink = "readable/" + codename + ".html"
    return f'''<a href={link} download={displayname}>{displayname}</a>
        <a href={nlink}><p style="text-align:right">Highlight Stream</p></a>
        <a href={rlink}><p style="text-align:right">Read Online</p></a>
        <br>'''

def insta_inject():
    with open("./include/insta_embed.html", "r") as html_inject:
        injection = [l.split("\n")[0] for l in html_inject.readlines()]
    injection = "".join(injection)
    return f'''
    <p>lilvids</p>
    {injection}
    '''

def yt_inject():
    with open("./include/yt_embed.html", "r") as html_inject:
        injection = [l.split("\n")[0] for l in html_inject.readlines()]
    injection = "".join(injection)
    return f'''
    <div class="content" id="content">
    {injection}
    </div>
    '''

def pdf_inject():
    with open("./include/pdf_inject.html", "r") as html_inject:
        injection = [l.split("\n")[0] for l in html_inject.readlines()]
    injection = "".join(injection)
    return f'''
    <div class="content" id="content">
    {injection}
    </div>
    '''

def javascript_inject():
    with open("javascript_inject.js", "r") as js_in:
        injection = [l.split("\n")[0] for l in js_in.readlines()]
    injection = "\n".join(injection)
    return f'''
    {injection}
    '''
def comment_inject():
    with open("./include/comment_inject.html", "r") as js_in:
        injection = [l.split("\n")[0] for l in js_in.readlines()]
    injection = "\n".join(injection)
    return f'''
    <div class="content" id="content">
    {injection}
    </div>
    '''

def inject_tweets():
    with open("./include/embedded_tweets.html", "r") as tweet_in:
        injection = [l.split("\n")[0] for l in tweet_in.readlines()]
    injection = "\n".join(injection)
    return f'''
    <div class="content" id="content">
    {injection}
    </div>
    '''



def test_button():
    return f'''
    <div class="outer-wrap">
      <h1 id="title"></h1>
      <div class="button-container">
        <a id="btn" class="btn btn-1">
          <svg>
            <rect x="0" y="0" fill="none" width="100%" height="100%"/>
          </svg>
          Create New Account
        </a>
      </div>
    </div>

    <div class="outer-wrap">
      <h1 id="title"></h1>
      <div class="button-container">
        <a id="btn2" class="btn btn-1">
          <svg>
            <rect x="0" y="0" fill="none" width="100%" height="100%"/>
          </svg>
          Log In
        </a>
      </div>
    </div>

    <div class="outer-wrap">
      <h1 id="title"></h1>
      <div class="button-container">
        <a id="btn3" class="btn btn-1">
          <svg>
            <rect x="0" y="0" fill="none" width="100%" height="100%"/>
          </svg>
          Push Data
        </a>
      </div>
    </div>

    <div class="outer-wrap">
    <p id="post"></p>
    <div class="button-container">
        <a id="btn4" class="btn btn-1">
          <svg>
            <rect x="0" y="0" fill="none" width="100%" height="100%"/>
          </svg>
          [Post]
        </a>
      </div>
    </div>
            
    '''

def gen_download_p(displayname, link, codename, xtype):
    return f'''<tr><td><a href={link} download={displayname}>{displayname}</a></td><td>{xtype}</td></tr><tr></tr>'''

def strip_underscores(blurb):
    return " ".join(blurb.split("_"))

def gen_readable(pageout, URL):
    print(URL)
    def remove_newlines(raw_text):
        split_lines = raw_text.split("\n")
        return (split_lines[0]," ".join(split_lines[1:-1]), split_lines[-1])
                
    req = urllib.request.Request(URL, headers={'User-Agent' : "Magic Browser"})
    remote_file = urllib.request.urlopen(req).read()
    remote_file_bytes = io.BytesIO(remote_file)
    pdfdoc = PyPDF2.PdfReader(remote_file_bytes)

    output_html = ""
    output_html += gen_head(strip_underscores(pageout), wtype="readable")
    output_html += "<div class='content' id='content'>"
    for i in range(len(pdfdoc.pages)):
        page_data = remove_newlines(pdfdoc.pages[i].extract_text())
        output_html += gen_pagenum(str(page_data[0]))
        output_html += gen_readp(str(page_data[1]))
        output_html += gen_pagenum(str(page_data[2]))

    output_html += "</div>"
    output_html += gen_tail()

    with open("readable/" + pageout + ".html", "w") as html_out:
        html_out.write(output_html)


def gen_wiki_page(codename):
    wiki = ""
    wiki += gen_head(codename, wtype="wiki")
    wiki += gen_p(strip_underscores(codename))
    try:
        with open("include/notes/" + codename + ".note", "r") as note_in:
            for line in [l.split("\n")[0] for l in note_in.readlines()]:
                pg_num = line.split(",")[-1]
                quote = ",".join(line.split(",")[:-1])
                if "??" in pg_num:
                    wiki += gen_p(quote)
                else:
                    wiki += gen_p(quote + " (pg " + pg_num + ")")
    except FileNotFoundError:
        with open("include/notes/" + codename + ".note", "w") as note_out:
            note_out.write("")
        wiki += gen_p("coming soon")
    wiki += gen_tail()

    with open("routes/" + codename + ".html", "w") as wiki_out:
        wiki_out.write(wiki)

'''
def gen_book_table():
    #creates the html for the main body of the index and all supporting pages that link from there
    table = f'<div class="content" id="content">'
    #for each book, add gen p with a href
    table_content = {"paper": [], "dissertation":[], "book": []}
    with open("include/main_table_data.csv", "r") as table_data:
        for line in [l.split("\n")[0] for l in table_data.readlines()]:
            name, link, text_type, codename = line.split(",")
            table_content[text_type].append((name, link, codename))
            gen_wiki_page(codename)
            if not os.path.isfile("readable/" + codename + ".html"):
                gen_readable(codename, link)
    table += "<h1>Phase 2: Digital Library</h1>" 
    table += "<h1>Papers</h1>"
    for paper_data in table_content["paper"]:
        table += gen_download_p(paper_data[0], paper_data[1], paper_data[2])
    table += "<h1>Dissertations</h1>"
    for dissertation_data in table_content["dissertation"]:
        table += gen_download_p(dissertation_data[0], dissertation_data[1], dissertation_data[2])
    table += "<h1>Books</h1>"
    for book_data in table_content["book"]:
        table += gen_download_p(book_data[0], book_data[1], book_data[2])
    table += "</div>"
    return table
'''            

def download_table():
    #creates the html for the main body of the index and all supporting pages that link from there
    table = f'<div class="content" id="content">'
    #for each book, add gen p with a href
    table_content = {"paper": [], "dissertation":[], "book": []}
    with open("include/main_table_data.csv", "r") as table_data:
        for line in [l.split("\n")[0] for l in table_data.readlines()]:
            name, link, text_type, codename = line.split(",")
            table_content[text_type].append((name, link, codename))
            gen_wiki_page(codename)
            if not os.path.isfile("readable/" + codename + ".html"):
                gen_readable(codename, link)
    table += "<h1>Downloads</h1>" 

    table += "<table class='livescans'>"
    for paper_data in table_content["paper"]:
        table += gen_download_p(paper_data[0], paper_data[1], paper_data[2], "Paper")
    for dissertation_data in table_content["dissertation"]:
        table += gen_download_p(dissertation_data[0], dissertation_data[1], dissertation_data[2], "PhD")
    for book_data in table_content["book"]:
        table += gen_download_p(book_data[0], book_data[1], book_data[2], "Book")

    table += "</table>"
    table += "</div>"
    return table

def gen_index():
    xapi = load_todoist()
    index = ""
    index += gen_head("Association Citation", wtype="main")
    #index += javascript_inject()
    index += gen_banner()
    index += comment_inject()
    #index += test_button()
    index += yt_inject()
    #index += pdf_inject()
    index += create_link_table(get_section(140213544, xapi), xapi)
    index += f'''<div class='content' id='content'><"a class="twitter-timeline" href="https://twitter.com/nonmarkov_field?ref_src=twsrc%5Etfw">Tweets by nonmarkov_field</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>'''
    index += download_table()
    index += gen_tail()

    with open("index.html", "w") as index_out:
        index_out.write(index)

def gen_twitter_gallery():
    html_payload = ""
    html_payload += gen_head("Twitter Gallery", wtype="main")
    html_payload += inject_tweets()
    html_payload += gen_tail()

    with open("twitter_gallery.html", "w") as html_out:
        html_out.write(html_payload)

def refresh():
    gen_twitter_gallery()
    gen_index()

def load_todoist():
    #access api token
    with open("api.token", "r") as key_in:
        api = TodoistAPI(str(key_in.readlines()[0].split("\n")[0]))
    return api

def get_section(s_id, api):
    try:
        titles = api.get_tasks(section_id=s_id)
        return titles
        #title = api.get_task(task_id=7480248679)
        #return title 
    except Exception as error:
        print(error)

def comments_from_task_id(t_id, api):
    try:
        comments = api.get_comments(task_id=t_id)
        return comments
    except Exception as error:
        print(error)

def format_title(title):
    title1 = title.replace("[", "")
    title2 = title1.replace("]", ": ")
    title = title2.replace("_", " ")
    return title

def get_table_row(title_task, api):
    content = title_task.content
    #c_date = title_task.created_at.split("T")[0]
    #x_year, x_month, x_day = c_date.split("-")
    #cc_date = x_month + "/" + x_day + "/" + x_year[2:]
    cc_date = get_date_by_comment(title_task.id, api)
    clink = "livescans/" + content + ".html"
    p_content = format_title(content)
    return f'''<tr><td>
    <tr><td><a href={clink}>{p_content}</a></td>
    <td>{cc_date}</td>
    </tr><tr></tr>
    '''
def create_link_table(titles, api):
    #titles should be full task objects
    table_html = "<div class='content' id='content'>"
    table_html += "<h1>Livescans</h1>"
    table_html += "<table class='livescans'>"
    #todo: sort by latest comment and supply that date
    dated_titles = sorted([[t] + [int(y) for y in get_date_by_comment(t.id, api).split("/")] for t in titles], key=lambda x: (x[3], x[1], x[2]),reverse=True)
    #titles_date_map = {t: get_date_by_comment(t.id, api).split("/") for t in titles}
    #dated_titles = sorted([get_date_by_comment(t.id, api).split("/") for t in titles], key=lambda x: (x[3], x[1], x[2]),reverse=True)
    #dated_titles = sorted([get_date_by_comment(t.id, api).split("/") for t in titles], key=lambda x: (x[3], x[1], x[2]),reverse=True)
    s_titles = [l[0] for l in dated_titles]
    for title in s_titles:
        table_html += get_table_row(title, api)
    table_html += "</table></div>"
    return table_html
    
def get_date_by_comment(t_id, api):
    test_c = comments_from_task_id(t_id, api)
    x_dates = []
    for c in test_c:
        x_dates.append([int(w) for w in c.posted_at.split("T")[0].split("-")])
    s_dates = sorted(x_dates, key=lambda x: (x[0], x[1], x[2]),reverse=True)
    x_year, x_month, x_day = s_dates[0]
    cc_date = str(x_month) + "/" + str(x_day) + "/" + str(x_year)[2:]
    return cc_date


#========RUNS=========#
refresh()
