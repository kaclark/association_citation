<html><head>
    <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
    <title>Markov_Chains</title>
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="../include/main.css"/>
    </head>
    <body>
    <div class="content">
        <h1>Markov Chains</h1>
        <p></p>
    </div>
    <div class="content" id="content">
    
    <p>Let Xi ∈ {A, . . . , E} denote the random variable that corresponds to X’s location after the ith move. Let X0 = A. From before, Pr[X1 = A] = 0 and Pr[X1 = L] = 1 4 for L ∈ {B, . . . , E}. We have Pr[X2 = A] = ∑ L∈{B,...,E} Pr[X2 = A|X1 = L] Pr[X1 = L] = 1 4 ∑ L∈{B,...,E} Pr[X2 = A|X1 = L] = 1 4 ∑ L∈{B,...,E} 1 4 = 1 pg 2</p>
    
    <p>WSY =       0 1 4 1 4 1 4 1 4 1 4 0 1 4 1 4 1 4 1 4 1 4 0 1 4 1 4 1 4 1 4 1 4 0 1 4 1 4 1 4 1 4 1 4 0 pg 3</p>
    
    <p>n its simplest sense, a discrete-time random or stochastic process is a collection of random variables indexed by time. The random variables track the pertinent aspects of the state pg 8</p>
    
    <p>of the system undergoing the process that we are trying to analyze. We denote such a process as {X(t) : t ∈ N} or {Xt : t ∈ N} pg 9</p>
    
    <p>Markov process is a memoryless6 stochastic process. Informally, this means that future outcomes of the process are based solely on the current state and hence are just as deter- mined as when given the process’s full history leading up to the current state. pg 10</p>
    
    <p>As we have already seen in a sense, we can depict such Markov processes graphically. We call such depictions Markov chains. We will now define this notion formally. Let X = {Xt : t ∈ N} be a Markov process, where Xt ∈ D for all t ∈ N. We define the Markov Chains for X as the set of weighted directed graphs GX ,t = {GX ,t = (D, Et, wt)} where Et = {(u, v) : Pr[Xt+1 = v|Xt = u] > 0} and wt(u, v) = Pr[Xt+1 = v|Xt = u] pg 10</p>
    
    </div>
    </body>
    </html>
    