#!/usr/bin/python3

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager 
import sys
import time
import urllib
import requests

options = webdriver.ChromeOptions()
options.add_experimental_option("detach", True)
#options.add_argument(r"--user-data-dir=/home/kaclark/.config/google-chrome")
#these options should attempt to load chrome with all user data
#options.add_argument(r'--user-data-dir=')
#PATH = "/Users/yourPath/Desktop/chromedriver"
#driver = webdriver.Chrome(PATH, options=options)

driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))
#driver.get('chrome://settings/clearBrowserData')
driver.get(sys.argv[1])
time.sleep(1)
tweet_info = driver.find_element(By.CLASS_NAME, "css-175oi2r").text
#imgResults = driver.find_elements(By.XPATH,"//img[contains(@class,'css-9pa8cd')]")
##img_info = driver.find_element(By.CLASS_NAME, "css-9pa8cd").

ignore_set = [
    'Don’t miss what’s happening', 
    'People on X are the first to know.', 
    'Log in', 
    'Sign up', 
    'Post', 
    'Conversation',
    'Follow',
    '·',
    ' Views',
    ' Reposts',
    ' Likes',
    ' Bookmarks',
    'Translate post',
    'Welcome to x.com!',
    'For more details, see our Privacy Policy: https://x.com/en/privacy',
    'We are letting you know that we are changing our URL, but your privacy and data protection settings remain the same.'
]
message_glued2 = tweet_info.replace("\n\n", "@@@")
message_glued = message_glued2.replace("]\n", "]@@@")
raw_info = message_glued.split("\n")
tweet_info = []
rejected = []
for info in raw_info:
    if info not in ignore_set:
        tweet_info.append(info)
    else:
        rejected.append(info)

info_map = {
    'profile_name': '', 
    'profile_account': '', 
    'post_text': '', 
    'post_date': '', 
    'views': '',  
    'reposts': '0',  
    'likes': '0',  
    'bookmarks': '0',
    'etc': ''
}

expected_rejects = ['views', 'reposts', 'likes', 'bookmarks']
formated_actual_rejects = [l.lstrip().lower() for l in rejected]
missing_fields = []
for reject in expected_rejects:
    if reject not in formated_actual_rejects:
        missing_fields.append(reject)

for k_ind, key in enumerate(info_map.keys()):
    if key in missing_fields:
        tweet_info.insert(k_ind, '0')
    info_map[key] = tweet_info[k_ind]
   
newlines_respliced = info_map['post_text'].replace("@@@", "\n\t")
for nline in newlines_respliced.split("\n\t"):
    if 'import' in nline:
        try:
            raw_author, raw_concept = nline.split('[')
            concept = raw_concept.replace("]", "")
            pre_author = raw_author.rstrip()
            x_action, author = pre_author.split(" ")
            print(x_action, author, concept)
        except ValueError:
            print(nline, "could not be partitioned properly")
            pass
info_map['post_text'] = newlines_respliced
#for kx, vx in info_map.items():
#    print(kx, vx)

def parse_relations(x_action, x_source, x_target):
    if x_action == "import":
        #load available sources
        #eg all_authors = load_authors()
        #   return all_authors[x_source][x_target]
        pass

def print_tweet(i_map):
    #i_map: dictionary mapping of information tags to details
    tweet_str = ""
    tweet_str += "\n\t" + i_map['profile_name'] + "\n\t" + i_map['profile_account'] + "\n\n"
    tweet_str += "\t" + i_map['post_text'] + "\n\n"
    tweet_str += "\t" + i_map['post_date'] + " Views: " + i_map['views'] + "\n"
    tweet_str += "\tRetweets: " + i_map['reposts'] + " Likes: " + i_map['likes'] + " Bookmarks: " + i_map['bookmarks'] + "\n"
    date_split = i_map['post_date'].split("·")
    date_reformat = date_split[0].replace(" ", "_").replace(":","_") + date_split[-1].lstrip().replace(" ", "_").replace(",", "") 
    
    with open("tw_dumps/" + date_reformat + ".txt", "w") as tw_dump:
        tw_dump.write("\t" + tweet_str + "\n")

    print(tweet_str)
    

print_tweet(info_map)
driver.close()
#src = []
#for img in imgResults:
#    src.append(img.get_attribute('src'))
#for i in range(len(src)):    
#    urllib.request.urlretrieve(str(src[i]),"tw_imgs/homepage_img{}.jpg".format(i))

#print(driver.page_source)
